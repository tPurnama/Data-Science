{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is intended to give you experience with supervised learning. Due Friday October 12th 2018, 5 pm EST.\n",
    "\n",
    "We will make use of the handwritten digit data set, http://yann.lecun.com/exdb/mnist/.\n",
    "There are four files you will need:\n",
    "* train-images-idx3-ubyte.gz:  training set images (9912422 bytes) \n",
    "* train-labels-idx1-ubyte.gz:  training set labels (28881 bytes) \n",
    "* t10k-images-idx3-ubyte.gz:   test set images (1648877 bytes) \n",
    "* t10k-labels-idx1-ubyte.gz:   test set labels (4542 bytes)\n",
    "\n",
    "Tasks:\n",
    "1. Unzip the above four files by using \n",
    "```shell\n",
    "gzip -d filename\n",
    "```\n",
    "You do not need to (and probably should not) add these larger data files to your repository, but you may if you wish.  The person grading this assignment will link the data files to your jupyter notebook.\n",
    "2. To load the data, it is easiest to install a python package which has already coded some import functions specifically for this data set:\n",
    "```shell\n",
    "pip install --user python-mnist\n",
    "```\n",
    "Then in your jupyter script, you can make use of:\n",
    "```python\n",
    "from mnist import MNIST\n",
    "data = MNIST('path/to/data')\n",
    "```\n",
    "3. For the training data set, display a few of these images (at least one of each hand written digit).  We have not given you explicit instruction on how to view image files, but hopefully you can figure out how to use matplotlib's imshow command.\n",
    "4. In your own words, explain how the K nearest neighbor (KNN) algorithm works.\n",
    "5. Develop python functions to compute the accuracy, sensitivity, specificity, precision and negative predictive value.\n",
    "6. Apply a KNN Classifier with n_neighbors = {3,4,5}.  For each model, \n",
    "    * compute the confusion matrix, as applied to the test set\n",
    "    * report the accuracy, sensitivity, specificity, precision and negative predictive value using your developed functions.\n",
    "    * compare the different models, \n",
    "7. Apply an SVM classifier.  Again, report the confusion matrix, as well as the accuracy, sensitivity, specificity, precision and negative predictive value.  How does the SVN classifier compare to the KNN classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer of Each Question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Unzip the above four files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As, the downloaded files from `http://yann.lecun.com/exdb/mnist/` are in the form of zip files, so we have to unzip the files before using it. We can unzip the file either from command prompt or directly from jupyter notebook itself by using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gzip -d \"C:/Users/Purnama/UN5550-Fall2018/projects/data/t10k-images-idx3-ubyte.gz\"\n",
    "! gzip -d \"C:/Users/Purnama/UN5550-Fall2018/projects/data/t10k-labels-idx1-ubyte.gz\"\n",
    "! gzip -d \"C:/Users/Purnama/UN5550-Fall2018/projects/data/train-images-idx3-ubyte.gz\"\n",
    "! gzip -d \"C:/Users/Purnama/UN5550-Fall2018/projects/data/train-labels-idx1-ubyte.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before loading the data, we have to install the package that support machine learning execution like `mnist` package. The following code will do the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --user python-mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to import the library that we need to enable the `minst` library, in this case, I also import all of the library that I am going to use for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mnist import MNIST # library for MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors, metrics, svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can load the data into the project by using the following code,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\train-labels-idx1-ubyte'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4961bbafb880>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#X, Y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_testing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Purnama\\AppData\\Roaming\\Python\\Python27\\site-packages\\mnist\\loader.pyc\u001b[0m in \u001b[0;36mload_training\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         ims, labels = self.load(os.path.join(self.path, self.train_img_fname),\n\u001b[1;32m--> 126\u001b[1;33m                                 os.path.join(self.path, self.train_lbl_fname))\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Purnama\\AppData\\Roaming\\Python\\Python27\\site-packages\\mnist\\loader.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, path_img, path_lbl, batch)\u001b[0m\n\u001b[0;32m    245\u001b[0m                                  '(start_point, batch_size)')\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_lbl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m             \u001b[0mmagic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\">II\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmagic\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2049\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Purnama\\AppData\\Roaming\\Python\\Python27\\site-packages\\mnist\\loader.pyc\u001b[0m in \u001b[0;36mopener\u001b[1;34m(self, path_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_fn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_lbl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '.\\\\train-labels-idx1-ubyte'"
     ]
    }
   ],
   "source": [
    "# This loads the dataset from system\n",
    "data = MNIST()\n",
    "#X, Y\n",
    "train_images, train_labels = data.load_training()\n",
    "test_images, test_labels =  data.load_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, there is an error prompt resulted from the code execution, this code is not working in my personal computer, however it works fine when I do the project using lab computer. As the above code are part of the question prompt, therefore I also included the information here.\n",
    "To remedy this issue, I use a code chunk that I found in `stackoverflow` forum. The following code will enable us to load the data into the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib import urlretrieve\n",
    "\n",
    "#retrieve the data from the source\n",
    "def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "\n",
    "# We then define functions for loading MNIST images and labels.\n",
    "# For convenience, we can also download the requested files if needed.\n",
    "import gzip\n",
    "\n",
    "#function for loading the file with images\n",
    "def load_mnist_images(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    # Read the inputs in Yann LeCun's binary format.\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    # The inputs are vectors now, we reshape them to monochrome 2D images,\n",
    "    # following the shape convention: (examples, channels, rows, columns)\n",
    "    data = data.reshape(-1, 1, 28, 28)\n",
    "    # The inputs come as bytes, we convert them to float32 in range [0,1].\n",
    "    return data / np.float32(256)\n",
    "\n",
    "#function for loading the files with labels\n",
    "def load_mnist_labels(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    # Read the labels in Yann LeCun's binary format.\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    # The labels are vectors of integers now, that's exactly what we want.\n",
    "    return data\n",
    "\n",
    "#call the function and add the value into variable\n",
    "X_train = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "y_train = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "X_test = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "y_test = load_mnist_labels('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "#source: https://stackoverflow.com/questions/43149272/cannot-get-mnist-database-through-anaconda-jupyter\n",
    "#Date taken: 10/12/2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code use `urlretrieve` library to retrieve the data from the url source. It then create a function to load the data and set a new variable to placed the return value from the function. We will used these new variable as our data source in this project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can convert the loaded data in the form of array to make it easier for us to call the data for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.asarray(X_train)\n",
    "train_labels = np.asarray(y_train)\n",
    "test_images = np.asarray(X_test)\n",
    "test_labels = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Display handwritten digit\n",
    "\n",
    " The task are asking to display a few of these images (at least one of each hand written digit) for the training dataset. We can do this by using `imshow` function from `matplotlib` library.\n",
    " \n",
    " The following code, will do the job by printing the image through looping in order to have some different output. As the digit showed will be randomize, so we can expand the number of trial to get as many digit as we want.\n",
    " The code will print the output in a form of 5 columns and 4 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row = 4\n",
    "column = 5\n",
    "for i in range(row * column):\n",
    "    image = np.array(train_images[i], dtype='float')\n",
    "    newShape = image.reshape(28, 28)\n",
    "    plt.subplot(row, column, i+1) \n",
    "    plt.imshow(newShape, cmap='gray')\n",
    "    plt.axis('off')  \n",
    "    \n",
    "#plot the result\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code, will do the loop and reshape the image into `28x28` dimension. The function `imshow` will take this new shape to construct the plot which will be displayed by using the command `plt.show()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-Nearest Neighbor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-Nearest neighbor algorithm is one of algorithm use for classifying an image. It rely on vectors. In short, the k-NN algorithm classified unknown data points through finding out the most common class among the `k` closest sample.\n",
    "In order for the k-NN algorithm to work, \n",
    "- First need to find the distance between the indicated vectors to make the classification by using distance metric function.\n",
    "- Then, make the classification by finding the nearest neighbor. In here, the category with the largest votes or the most appear in the `k` closest training points will be used as the label of the testing point.\n",
    "- In addition, we can split our data into two sets: a training set and a testing set to train the classifier using various value of `k`, find the set that give the best performance through accuracy and also evaluate the classifier.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Notes: \n",
    "\n",
    "References: https://gurus.pyimagesearch.com/lesson-sample-k-nearest-neighbor-classification/\n",
    "\n",
    "Accessed: 10/12/2018\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Develop Function\n",
    "Develop python functions to compute the accuracy, sensitivity, specificity, precision and negative predictive value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As required by the question, the following code will construct some function to compute the accuracy, sensitivity, specificity, precision, and negative predictive value. In this case, we define sensitivity as recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for computing the accuracy\n",
    "def accuracy(tp, fp, tn, fn):\n",
    "    \"\"\"(TP+TN)/(TP+TN+FP+FN)\"\"\"\n",
    "    return ((tp+tn)/(tp+fp+fn+tn))\n",
    "\n",
    "#function for computing the recall\n",
    "def recall(tp, fp, tn, fn):\n",
    "    \"\"\"TP/Real Positives\"\"\"\n",
    "    return tp/(tp+fn)\n",
    "\n",
    "#function for computing the specificity\n",
    "def specificity (tp, fp, tn, fn):\n",
    "    \"\"\"TN/Real Negatives\"\"\"\n",
    "    return tn/(tn+fp)\n",
    "\n",
    "#function for computing the precision\n",
    "def precision(tp, fp, tn, fn):\n",
    "    \"\"\"TP/(TP+FP)\"\"\"\n",
    "    return tp/(tp+fp)\n",
    "\n",
    "#function for computing the negative predictive value\n",
    "def NegativePredictiveValue(tp, fp, tn, fn):\n",
    "    \"\"\"Tn/Predicted Negatives\"\"\"\n",
    "    return tn/(tn+fn)\n",
    "\n",
    "#function for computing the f1_score\n",
    "def f1_score(tp, fp, tn, fn):\n",
    "    \"\"\"Harmonic average of precision and recall\"\"\"\n",
    "    p=precision(tp, fp, tn, fn)\n",
    "    r=recall(tp, fp, tn, fn)\n",
    "    return 2*p*r/(p+r)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code will take 4 arguments which are the true positive, false positive, true negative, and false negative from our data set. It then compute the variable based on the formula of each items or function. The execution of the code will be shown in the later part.\n",
    "\n",
    "\n",
    "\n",
    "* TP: true positives: classifier predicts a sample as positive in accordance with ground truth\n",
    "* FP: false positive: classifier predicts a sample as positive in conflict with ground truth\n",
    "* TN: true negative:  classifier predicts a sample as negative in accordance with ground truth\n",
    "* FN: false negative: classifier predicts a sample as negative in conflict with ground truth\n",
    "\n",
    "\n",
    "\n",
    "Below is the formula use on the function:\n",
    "* accuracy: $$ \\text{accuracy} = \\frac{\\text{TP + TN}}{\\text{TP + TN + FP + FN}}.$$\n",
    "* sensitivity:  $$ \\text{sensitivity} = \\frac{\\text{TP}}{\\text{TP + FN}}$$\n",
    "* specificity: $$ \\text{specificity} = \\frac{\\text{TN}}{\\text{TN + FP} }$$\n",
    "* precision: $$ \\text{precision} = \\frac{\\text{TP}}{\\text{TP + FP} }$$\n",
    "* Negative Predictive Value: $$ \\text{NPV} = \\frac{\\text{TN}}{\\text{TN + FN} }$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using KNN Classifier\n",
    "\n",
    "The task is asking to apply a KNN Classifier with n_neighbors = {3,4,5}.  For each model, \n",
    "   * compute the confusion matrix, as applied to the test set\n",
    "   * report the accuracy, sensitivity, specificity, precision and negative predictive value using your developed functions.\n",
    "   * compare the different models, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle this task, first we will do the code insequence with the order of the task. It means that we will compute the confusion matrix as the first step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dataset has quite a lot of data, first we will try to limit data from the dataset that we are going to use to complete the task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images1 = X_train[1:1000]\n",
    "train_labels1 = y_train[1:1000]\n",
    "test_images1 = X_test[1:1000]\n",
    "test_labels1 = y_test[1:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code will do the job, however, as I want to make sure that each data has the same dimension and want to separate between training and testing set, I will use the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data points: 1347\n",
      "testing data points: 450\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# load the MNIST digits dataset\n",
    "mnist = datasets.load_digits()\n",
    " \n",
    "# take the MNIST data and construct the training and testing split, using 75% of the\n",
    "# data for training and 25% for testing\n",
    "(trainImages, testImages, trainLabels, testLabels) = train_test_split(np.array(mnist.data),\n",
    "\tmnist.target, test_size=0.25, random_state=50)\n",
    " \n",
    "# show the sizes of each data split\n",
    "print(\"training data points: {}\".format(len(trainLabels)))\n",
    "print(\"testing data points: {}\".format(len(testLabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can apply the KNN classifier and define the number of neighbors that we will use to train and predict the data. \n",
    "\n",
    "We will print out the confusion matrix and the accuracy score in this part. The confusion matrix was used to evaluate the accuracy of a classification. The accuracy score will show how accurate the prediction is. There are three models that was asked from the question (3, 4, 5) as the value of the neighbor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. For Model = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In here, we will define the neighbor value as 3, train the classifier and predict it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION ON TESTING DATA\n",
      "Confusion Matrix:\n",
      "[[52  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 47  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 36  0  0  0  1  0  1]\n",
      " [ 0  0  0  0 39  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 41  1  0  0  1]\n",
      " [ 0  0  0  0  0  0 49  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 45  0  1]\n",
      " [ 0  1  0  0  0  0  0  0 35  1]\n",
      " [ 0  0  0  1  1  0  0  0  1 46]]\n",
      "Accuracy Score:\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# re-train our classifier using the best k value and predict the labels of the\n",
    "# test data\n",
    "knnModel3 = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "knnModel3.fit(trainImages, trainLabels)\n",
    "predictions3 = knnModel3.predict(testImages)\n",
    " \n",
    "# show a final classification report demonstrating the confusion matrix and\n",
    "# accuracy of the classifier \n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(testLabels, predictions3))\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(predictions3, testLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above result shows that the prediction is almost 98 percent accurate.\n",
    "\n",
    "We can also construct the confusion matrix by using a loop shown in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix code for 10x10\n",
    "C = np.empty([10,10])\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        C[i,j] = np.sum(np.logical_and(predictions3==i, testLabels==j))\n",
    "\n",
    "#print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will continue to the next set of task that was mentioned in the question which is reporting the accuracy, sensitivity, specificity, precision and negative predictive value using functions and compare the different models.\n",
    "\n",
    "The following code will first define the false positive, false negative, true positive and true negative value of each model. Then it will call the function that we built in the previous question and will print out the result of each. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is use to define the variable or argument to be used to call the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the value\n",
    "fp3 = C.sum(axis=0)-np.diag(C)\n",
    "fn3 = C.sum(axis=1)-np.diag(C)\n",
    "tp3 = np.diag(C)\n",
    "tn3 = C.sum()-np.diag(fp + fn + tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will call the function that we previously declared. It will then convert the value in the form of dataframe to make the display a more visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc3 = pd.DataFrame(accuracy(tp3,fp3,tn3,fn3))\n",
    "rec3 = pd.DataFrame(recall(tp3,fp3,tn3,fn3))\n",
    "speci3 = pd.DataFrame(specificity(tp3,fp3,tn3,fn3))\n",
    "prec3 = pd.DataFrame(precision(tp3,fp3,tn3,fn3))\n",
    "negative3 = pd.DataFrame(NegativePredictiveValue(tp3,fp3,tn3,fn3))\n",
    "f1score3 = pd.DataFrame(f1_score(tp3,fp3,tn3,fn3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will print out the result from the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################\n",
      "Accuracy: \n",
      "     0         1    2         3         4         5         6         7  \\\n",
      "0  1.0  0.998004  1.0  0.993865  0.997959  0.995943  0.998000  0.995976   \n",
      "1  1.0  0.997778  1.0  0.993865  0.997959  0.995943  0.998000  0.995976   \n",
      "2  1.0  0.998004  1.0  0.993865  0.997959  0.995943  0.998000  0.995976   \n",
      "3  1.0  0.998004  1.0  0.993333  0.997959  0.995943  0.998000  0.995976   \n",
      "4  1.0  0.998004  1.0  0.993865  0.997778  0.995943  0.998000  0.995976   \n",
      "5  1.0  0.998004  1.0  0.993865  0.997959  0.995556  0.998000  0.995976   \n",
      "6  1.0  0.998004  1.0  0.993865  0.997959  0.995943  0.997778  0.995976   \n",
      "7  1.0  0.998004  1.0  0.993865  0.997959  0.995943  0.998000  0.995556   \n",
      "8  1.0  0.998004  1.0  0.993865  0.997959  0.995943  0.998000  0.995976   \n",
      "9  1.0  0.998004  1.0  0.993865  0.997959  0.995943  0.998000  0.995976   \n",
      "\n",
      "          8         9  \n",
      "0  0.993852  0.986083  \n",
      "1  0.993852  0.986083  \n",
      "2  0.993852  0.986083  \n",
      "3  0.993852  0.986083  \n",
      "4  0.993852  0.986083  \n",
      "5  0.993852  0.986083  \n",
      "6  0.993852  0.986083  \n",
      "7  0.993852  0.986083  \n",
      "8  0.993333  0.986083  \n",
      "9  0.993852  0.984444  \n",
      "####################################################################\n",
      "Recall: \n",
      "          0\n",
      "0  1.000000\n",
      "1  0.980392\n",
      "2  1.000000\n",
      "3  0.972973\n",
      "4  0.975000\n",
      "5  1.000000\n",
      "6  0.980000\n",
      "7  0.978261\n",
      "8  0.972222\n",
      "9  0.920000\n",
      "####################################################################\n",
      "Specificity: \n",
      "     0    1    2         3    4         5    6         7         8         9\n",
      "0  1.0  1.0  1.0  0.995575  1.0  0.995575  1.0  0.997783  0.995575  0.993377\n",
      "1  1.0  1.0  1.0  0.995575  1.0  0.995575  1.0  0.997783  0.995575  0.993377\n",
      "2  1.0  1.0  1.0  0.995575  1.0  0.995575  1.0  0.997783  0.995575  0.993377\n",
      "3  1.0  1.0  1.0  0.995157  1.0  0.995575  1.0  0.997783  0.995575  0.993377\n",
      "4  1.0  1.0  1.0  0.995575  1.0  0.995575  1.0  0.997783  0.995575  0.993377\n",
      "5  1.0  1.0  1.0  0.995575  1.0  0.995110  1.0  0.997783  0.995575  0.993377\n",
      "6  1.0  1.0  1.0  0.995575  1.0  0.995575  1.0  0.997783  0.995575  0.993377\n",
      "7  1.0  1.0  1.0  0.995575  1.0  0.995575  1.0  0.997525  0.995575  0.993377\n",
      "8  1.0  1.0  1.0  0.995575  1.0  0.995575  1.0  0.997783  0.995169  0.993377\n",
      "9  1.0  1.0  1.0  0.995575  1.0  0.995575  1.0  0.997783  0.995575  0.992500\n",
      "####################################################################\n",
      "Precision: \n",
      "          0\n",
      "0  1.000000\n",
      "1  1.000000\n",
      "2  1.000000\n",
      "3  0.947368\n",
      "4  1.000000\n",
      "5  0.953488\n",
      "6  1.000000\n",
      "7  0.978261\n",
      "8  0.945946\n",
      "9  0.938776\n",
      "####################################################################\n",
      "Negative Predictive Value: \n",
      "     0         1    2         3         4    5         6         7         8  \\\n",
      "0  1.0  0.997783  1.0  0.997783  0.997783  1.0  0.997783  0.997783  0.997783   \n",
      "1  1.0  0.997500  1.0  0.997783  0.997783  1.0  0.997783  0.997783  0.997783   \n",
      "2  1.0  0.997783  1.0  0.997783  0.997783  1.0  0.997783  0.997783  0.997783   \n",
      "3  1.0  0.997783  1.0  0.997573  0.997783  1.0  0.997783  0.997783  0.997783   \n",
      "4  1.0  0.997783  1.0  0.997783  0.997567  1.0  0.997783  0.997783  0.997783   \n",
      "5  1.0  0.997783  1.0  0.997783  0.997783  1.0  0.997783  0.997783  0.997783   \n",
      "6  1.0  0.997783  1.0  0.997783  0.997783  1.0  0.997506  0.997783  0.997783   \n",
      "7  1.0  0.997783  1.0  0.997783  0.997783  1.0  0.997783  0.997525  0.997783   \n",
      "8  1.0  0.997783  1.0  0.997783  0.997783  1.0  0.997783  0.997783  0.997579   \n",
      "9  1.0  0.997783  1.0  0.997783  0.997783  1.0  0.997783  0.997783  0.997783   \n",
      "\n",
      "          9  \n",
      "0  0.991189  \n",
      "1  0.991189  \n",
      "2  0.991189  \n",
      "3  0.991189  \n",
      "4  0.991189  \n",
      "5  0.991189  \n",
      "6  0.991189  \n",
      "7  0.991189  \n",
      "8  0.991189  \n",
      "9  0.990025  \n",
      "####################################################################\n",
      "F1 Score:\n",
      "          0\n",
      "0  1.000000\n",
      "1  0.990099\n",
      "2  1.000000\n",
      "3  0.960000\n",
      "4  0.987342\n",
      "5  0.976190\n",
      "6  0.989899\n",
      "7  0.978261\n",
      "8  0.958904\n",
      "9  0.929293\n",
      "####################################################################\n"
     ]
    }
   ],
   "source": [
    "print(\"####################################################################\")\n",
    "print(\"Accuracy: \")\n",
    "print(acc3)\n",
    "print(\"####################################################################\")\n",
    "print(\"Recall: \")\n",
    "print(rec3)\n",
    "print(\"####################################################################\")\n",
    "print(\"Specificity: \")\n",
    "print(speci3)\n",
    "print(\"####################################################################\")\n",
    "print(\"Precision: \")\n",
    "print(prec3)\n",
    "print(\"####################################################################\")\n",
    "print(\"Negative Predictive Value: \")\n",
    "print(negative3)\n",
    "print(\"####################################################################\")\n",
    "print(\"F1 Score:\")\n",
    "print(f1score3)\n",
    "print(\"####################################################################\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For Model = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In here, we will define the neighbor value as 4, train the classifier and predict it. It will also print out the confusion matrix and accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### EVALUATION ON TESTING DATA #####\n",
      "Confusion Matrix:\n",
      "[[52  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 47  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 36  0  0  0  1  0  1]\n",
      " [ 0  0  0  0 39  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 41  1  0  0  1]\n",
      " [ 0  0  0  0  0  0 49  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 46  0  0]\n",
      " [ 0  1  1  0  0  0  0  0 34  1]\n",
      " [ 0  0  0  1  1  0  0  0  1 46]]\n",
      "Accuracy Score:\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# re-train our classifier using the best k value and predict the labels of the\n",
    "# test data\n",
    "knnModel4 = neighbors.KNeighborsClassifier(n_neighbors=4)\n",
    "knnModel4.fit(trainImages, trainLabels)\n",
    "predictions4 = knnModel4.predict(testImages)\n",
    " \n",
    "# show a final classification report demonstrating the accuracy of the classifier\n",
    "# for each of the digits\n",
    "print(\"##### EVALUATION ON TESTING DATA #####\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(testLabels, predictions4))\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(predictions4, testLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above result shows that the prediction is almost 98 percent accurate.\n",
    "\n",
    "We can also construct the confusion matrix by using a loop shown in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix code for 10x10\n",
    "C = np.empty([10,10])\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        C[i,j] = np.sum(np.logical_and(predictions4==i, testLabels==j))\n",
    "\n",
    "#print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will continue to the next set of task that was mentioned in the question which is reporting the accuracy, sensitivity, specificity, precision and negative predictive value using functions and compare the different models.\n",
    "\n",
    "The following code will first define the false positive, false negative, true positive and true negative value of each model. Then it will call the function that we built in the previous question and will print out the result of each. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is use to define the variable or argument to be used to call the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the value\n",
    "fp4 = C.sum(axis=0)-np.diag(C)\n",
    "fn4 = C.sum(axis=1)-np.diag(C)\n",
    "tp4 = np.diag(C)\n",
    "tn4 = C.sum()-np.diag(fp + fn + tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will call the function that we previously declared. It will then convert the value in the form of dataframe to make the display a more visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc4 = pd.DataFrame(accuracy(tp4,fp4,tn4,fn4))\n",
    "rec4 = pd.DataFrame(recall(tp4,fp4,tn4,fn4))\n",
    "speci4 = pd.DataFrame(specificity(tp4,fp4,tn4,fn4))\n",
    "prec4 = pd.DataFrame(precision(tp4,fp4,tn4,fn4))\n",
    "negative4 = pd.DataFrame(NegativePredictiveValue(tp4,fp4,tn4,fn4))\n",
    "f1score4 = pd.DataFrame(f1_score(tp4,fp4,tn4,fn4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will print out the result from the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################\n",
      "Accuracy: \n",
      "     0         1         2         3         4         5         6         7  \\\n",
      "0  1.0  0.998004  0.997992  0.993865  0.997959  0.995943  0.998000  0.997988   \n",
      "1  1.0  0.997778  0.997992  0.993865  0.997959  0.995943  0.998000  0.997988   \n",
      "2  1.0  0.998004  0.997783  0.993865  0.997959  0.995943  0.998000  0.997988   \n",
      "3  1.0  0.998004  0.997992  0.993333  0.997959  0.995943  0.998000  0.997988   \n",
      "4  1.0  0.998004  0.997992  0.993865  0.997778  0.995943  0.998000  0.997988   \n",
      "5  1.0  0.998004  0.997992  0.993865  0.997959  0.995556  0.998000  0.997988   \n",
      "6  1.0  0.998004  0.997992  0.993865  0.997959  0.995943  0.997778  0.997988   \n",
      "7  1.0  0.998004  0.997992  0.993865  0.997959  0.995943  0.998000  0.997778   \n",
      "8  1.0  0.998004  0.997992  0.993865  0.997959  0.995943  0.998000  0.997988   \n",
      "9  1.0  0.998004  0.997992  0.993865  0.997959  0.995943  0.998000  0.997988   \n",
      "\n",
      "          8         9  \n",
      "0  0.991803  0.988048  \n",
      "1  0.991803  0.988048  \n",
      "2  0.991803  0.988048  \n",
      "3  0.991803  0.988048  \n",
      "4  0.991803  0.988048  \n",
      "5  0.991803  0.988048  \n",
      "6  0.991803  0.988048  \n",
      "7  0.991803  0.988048  \n",
      "8  0.991111  0.988048  \n",
      "9  0.991803  0.986637  \n",
      "####################################################################\n",
      "Recall: \n",
      "          0\n",
      "0  1.000000\n",
      "1  0.980392\n",
      "2  0.979167\n",
      "3  0.972973\n",
      "4  0.975000\n",
      "5  1.000000\n",
      "6  0.980000\n",
      "7  0.978723\n",
      "8  0.971429\n",
      "9  0.938776\n",
      "####################################################################\n",
      "Specificity: \n",
      "     0    1    2         3    4         5    6    7         8         9\n",
      "0  1.0  1.0  1.0  0.995575  1.0  0.995575  1.0  1.0  0.993377  0.993377\n",
      "1  1.0  1.0  1.0  0.995575  1.0  0.995575  1.0  1.0  0.993377  0.993377\n",
      "2  1.0  1.0  1.0  0.995575  1.0  0.995575  1.0  1.0  0.993377  0.993377\n",
      "3  1.0  1.0  1.0  0.995157  1.0  0.995575  1.0  1.0  0.993377  0.993377\n",
      "4  1.0  1.0  1.0  0.995575  1.0  0.995575  1.0  1.0  0.993377  0.993377\n",
      "5  1.0  1.0  1.0  0.995575  1.0  0.995110  1.0  1.0  0.993377  0.993377\n",
      "6  1.0  1.0  1.0  0.995575  1.0  0.995575  1.0  1.0  0.993377  0.993377\n",
      "7  1.0  1.0  1.0  0.995575  1.0  0.995575  1.0  1.0  0.993377  0.993377\n",
      "8  1.0  1.0  1.0  0.995575  1.0  0.995575  1.0  1.0  0.992771  0.993377\n",
      "9  1.0  1.0  1.0  0.995575  1.0  0.995575  1.0  1.0  0.993377  0.992500\n",
      "####################################################################\n",
      "Precision: \n",
      "          0\n",
      "0  1.000000\n",
      "1  1.000000\n",
      "2  1.000000\n",
      "3  0.947368\n",
      "4  1.000000\n",
      "5  0.953488\n",
      "6  1.000000\n",
      "7  1.000000\n",
      "8  0.918919\n",
      "9  0.938776\n",
      "####################################################################\n",
      "Negative Predictive Value: \n",
      "     0         1         2         3         4    5         6         7  \\\n",
      "0  1.0  0.997783  0.997783  0.997783  0.997783  1.0  0.997783  0.997783   \n",
      "1  1.0  0.997500  0.997783  0.997783  0.997783  1.0  0.997783  0.997783   \n",
      "2  1.0  0.997783  0.997525  0.997783  0.997783  1.0  0.997783  0.997783   \n",
      "3  1.0  0.997783  0.997783  0.997573  0.997783  1.0  0.997783  0.997783   \n",
      "4  1.0  0.997783  0.997783  0.997783  0.997567  1.0  0.997783  0.997783   \n",
      "5  1.0  0.997783  0.997783  0.997783  0.997783  1.0  0.997783  0.997783   \n",
      "6  1.0  0.997783  0.997783  0.997783  0.997783  1.0  0.997506  0.997783   \n",
      "7  1.0  0.997783  0.997783  0.997783  0.997783  1.0  0.997783  0.997525   \n",
      "8  1.0  0.997783  0.997783  0.997783  0.997783  1.0  0.997783  0.997783   \n",
      "9  1.0  0.997783  0.997783  0.997783  0.997783  1.0  0.997783  0.997783   \n",
      "\n",
      "          8         9  \n",
      "0  0.997783  0.993377  \n",
      "1  0.997783  0.993377  \n",
      "2  0.997783  0.993377  \n",
      "3  0.997783  0.993377  \n",
      "4  0.997783  0.993377  \n",
      "5  0.997783  0.993377  \n",
      "6  0.997783  0.993377  \n",
      "7  0.997783  0.993377  \n",
      "8  0.997579  0.993377  \n",
      "9  0.997783  0.992500  \n",
      "####################################################################\n",
      "F1 Score:\n",
      "          0\n",
      "0  1.000000\n",
      "1  0.990099\n",
      "2  0.989474\n",
      "3  0.960000\n",
      "4  0.987342\n",
      "5  0.976190\n",
      "6  0.989899\n",
      "7  0.989247\n",
      "8  0.944444\n",
      "9  0.938776\n",
      "####################################################################\n"
     ]
    }
   ],
   "source": [
    "print(\"####################################################################\")\n",
    "print(\"Accuracy: \")\n",
    "print(acc4)\n",
    "print(\"####################################################################\")\n",
    "print(\"Recall: \")\n",
    "print(rec4)\n",
    "print(\"####################################################################\")\n",
    "print(\"Specificity: \")\n",
    "print(speci4)\n",
    "print(\"####################################################################\")\n",
    "print(\"Precision: \")\n",
    "print(prec4)\n",
    "print(\"####################################################################\")\n",
    "print(\"Negative Predictive Value: \")\n",
    "print(negative4)\n",
    "print(\"####################################################################\")\n",
    "print(\"F1 Score:\")\n",
    "print(f1score4)\n",
    "print(\"####################################################################\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For Model = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In here, we will define the neighbor value as 5, train the classifier and predict it. It will also print out the confusion matrix and accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### EVALUATION ON TESTING DATA #####\n",
      "Confusion Matrix:\n",
      "[[52  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 47  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 35  0  1  0  1  0  1]\n",
      " [ 0  0  0  0 38  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 41  1  0  0  1]\n",
      " [ 0  0  0  0  0  0 49  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 46  0  0]\n",
      " [ 0  1  1  0  0  0  0  0 34  1]\n",
      " [ 0  0  0  1  1  0  0  0  1 46]]\n",
      "Accuracy Score:\n",
      "0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "# re-train our classifier using the best k value and predict the labels of the\n",
    "# test data\n",
    "knnModel5 = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knnModel5.fit(trainImages, trainLabels)\n",
    "predictions5 = knnModel5.predict(testImages)\n",
    " \n",
    "# show a final classification report demonstrating the accuracy of the classifier\n",
    "# for each of the digits\n",
    "print(\"##### EVALUATION ON TESTING DATA #####\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(testLabels, predictions5))\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(predictions5, testLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above result shows that the prediction is almost 98 percent accurate.\n",
    "\n",
    "We can also construct the confusion matrix by using a loop shown in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix code for 10x10\n",
    "C = np.empty([10,10])\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        C[i,j] = np.sum(np.logical_and(predictions5==i, testLabels==j))\n",
    "\n",
    "#print(C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will continue to the next set of task that was mentioned in the question which is reporting the accuracy, sensitivity, specificity, precision and negative predictive value using functions and compare the different models.\n",
    "\n",
    "The following code will first define the false positive, false negative, true positive and true negative value of each model. Then it will call the function that we built in the previous question and will print out the result of each. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is use to define the variable or argument to be used to call the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the value\n",
    "fp5 = C.sum(axis=0)-np.diag(C)\n",
    "fn5 = C.sum(axis=1)-np.diag(C)\n",
    "tp5 = np.diag(C)\n",
    "tn5 = C.sum()-np.diag(fp + fn + tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will call the function that we previously declared. It will then convert the value in the form of dataframe to make the display a more visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc5 = pd.DataFrame(accuracy(tp5,fp5,tn5,fn5))\n",
    "rec5 = pd.DataFrame(recall(tp5,fp5,tn5,fn5))\n",
    "speci5 = pd.DataFrame(specificity(tp5,fp5,tn5,fn5))\n",
    "prec5 = pd.DataFrame(precision(tp5,fp5,tn5,fn5))\n",
    "negative5 = pd.DataFrame(NegativePredictiveValue(tp5,fp5,tn5,fn5))\n",
    "f1score5 = pd.DataFrame(f1_score(tp5,fp5,tn5,fn5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will print out the result from the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################\n",
      "Accuracy: \n",
      "     0         1         2         3         4         5         6         7  \\\n",
      "0  1.0  0.998004  0.997992  0.991820  0.995918  0.993927  0.998000  0.995984   \n",
      "1  1.0  0.997778  0.997992  0.991820  0.995918  0.993927  0.998000  0.995984   \n",
      "2  1.0  0.998004  0.997783  0.991820  0.995918  0.993927  0.998000  0.995984   \n",
      "3  1.0  0.998004  0.997992  0.991111  0.995918  0.993927  0.998000  0.995984   \n",
      "4  1.0  0.998004  0.997992  0.991820  0.995556  0.993927  0.998000  0.995984   \n",
      "5  1.0  0.998004  0.997992  0.991820  0.995918  0.993348  0.998000  0.995984   \n",
      "6  1.0  0.998004  0.997992  0.991820  0.995918  0.993927  0.997778  0.995984   \n",
      "7  1.0  0.998004  0.997992  0.991820  0.995918  0.993927  0.998000  0.995565   \n",
      "8  1.0  0.998004  0.997992  0.991820  0.995918  0.993927  0.998000  0.995984   \n",
      "9  1.0  0.998004  0.997992  0.991820  0.995918  0.993927  0.998000  0.995984   \n",
      "\n",
      "          8         9  \n",
      "0  0.991803  0.988048  \n",
      "1  0.991803  0.988048  \n",
      "2  0.991803  0.988048  \n",
      "3  0.991803  0.988048  \n",
      "4  0.991803  0.988048  \n",
      "5  0.991803  0.988048  \n",
      "6  0.991803  0.988048  \n",
      "7  0.991803  0.988048  \n",
      "8  0.991111  0.988048  \n",
      "9  0.991803  0.986637  \n",
      "####################################################################\n",
      "Recall: \n",
      "          0\n",
      "0  1.000000\n",
      "1  0.980392\n",
      "2  0.979167\n",
      "3  0.972222\n",
      "4  0.974359\n",
      "5  0.976190\n",
      "6  0.980000\n",
      "7  0.958333\n",
      "8  0.971429\n",
      "9  0.938776\n",
      "####################################################################\n",
      "Specificity: \n",
      "     0    1    2         3         4         5    6    7         8         9\n",
      "0  1.0  1.0  1.0  0.993377  0.997783  0.995575  1.0  1.0  0.993377  0.993377\n",
      "1  1.0  1.0  1.0  0.993377  0.997783  0.995575  1.0  1.0  0.993377  0.993377\n",
      "2  1.0  1.0  1.0  0.993377  0.997783  0.995575  1.0  1.0  0.993377  0.993377\n",
      "3  1.0  1.0  1.0  0.992754  0.997783  0.995575  1.0  1.0  0.993377  0.993377\n",
      "4  1.0  1.0  1.0  0.993377  0.997567  0.995575  1.0  1.0  0.993377  0.993377\n",
      "5  1.0  1.0  1.0  0.993377  0.997783  0.995110  1.0  1.0  0.993377  0.993377\n",
      "6  1.0  1.0  1.0  0.993377  0.997783  0.995575  1.0  1.0  0.993377  0.993377\n",
      "7  1.0  1.0  1.0  0.993377  0.997783  0.995575  1.0  1.0  0.993377  0.993377\n",
      "8  1.0  1.0  1.0  0.993377  0.997783  0.995575  1.0  1.0  0.992771  0.993377\n",
      "9  1.0  1.0  1.0  0.993377  0.997783  0.995575  1.0  1.0  0.993377  0.992500\n",
      "####################################################################\n",
      "Precision: \n",
      "          0\n",
      "0  1.000000\n",
      "1  1.000000\n",
      "2  1.000000\n",
      "3  0.921053\n",
      "4  0.974359\n",
      "5  0.953488\n",
      "6  1.000000\n",
      "7  1.000000\n",
      "8  0.918919\n",
      "9  0.938776\n",
      "####################################################################\n",
      "Negative Predictive Value: \n",
      "     0         1         2         3         4         5         6         7  \\\n",
      "0  1.0  0.997783  0.997783  0.997783  0.997783  0.997783  0.997783  0.995575   \n",
      "1  1.0  0.997500  0.997783  0.997783  0.997783  0.997783  0.997783  0.995575   \n",
      "2  1.0  0.997783  0.997525  0.997783  0.997783  0.997783  0.997783  0.995575   \n",
      "3  1.0  0.997783  0.997783  0.997573  0.997783  0.997783  0.997783  0.995575   \n",
      "4  1.0  0.997783  0.997783  0.997783  0.997567  0.997783  0.997783  0.995575   \n",
      "5  1.0  0.997783  0.997783  0.997783  0.997783  0.997549  0.997783  0.995575   \n",
      "6  1.0  0.997783  0.997783  0.997783  0.997783  0.997783  0.997506  0.995575   \n",
      "7  1.0  0.997783  0.997783  0.997783  0.997783  0.997783  0.997783  0.995062   \n",
      "8  1.0  0.997783  0.997783  0.997783  0.997783  0.997783  0.997783  0.995575   \n",
      "9  1.0  0.997783  0.997783  0.997783  0.997783  0.997783  0.997783  0.995575   \n",
      "\n",
      "          8         9  \n",
      "0  0.997783  0.993377  \n",
      "1  0.997783  0.993377  \n",
      "2  0.997783  0.993377  \n",
      "3  0.997783  0.993377  \n",
      "4  0.997783  0.993377  \n",
      "5  0.997783  0.993377  \n",
      "6  0.997783  0.993377  \n",
      "7  0.997783  0.993377  \n",
      "8  0.997579  0.993377  \n",
      "9  0.997783  0.992500  \n",
      "####################################################################\n",
      "F1 Score:\n",
      "          0\n",
      "0  1.000000\n",
      "1  0.990099\n",
      "2  0.989474\n",
      "3  0.945946\n",
      "4  0.974359\n",
      "5  0.964706\n",
      "6  0.989899\n",
      "7  0.978723\n",
      "8  0.944444\n",
      "9  0.938776\n",
      "####################################################################\n"
     ]
    }
   ],
   "source": [
    "print(\"####################################################################\")\n",
    "print(\"Accuracy: \")\n",
    "print(acc5)\n",
    "print(\"####################################################################\")\n",
    "print(\"Recall: \")\n",
    "print(rec5)\n",
    "print(\"####################################################################\")\n",
    "print(\"Specificity: \")\n",
    "print(speci5)\n",
    "print(\"####################################################################\")\n",
    "print(\"Precision: \")\n",
    "print(prec5)\n",
    "print(\"####################################################################\")\n",
    "print(\"Negative Predictive Value: \")\n",
    "print(negative5)\n",
    "print(\"####################################################################\")\n",
    "print(\"F1 Score:\")\n",
    "print(f1score5)\n",
    "print(\"####################################################################\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also able to directly display the precision, recall, f1 score, and support by using classification_report function. The code below will do the report for each of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION ON TESTING DATA | Model = 3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        52\n",
      "          1       1.00      0.98      0.99        51\n",
      "          2       1.00      1.00      1.00        47\n",
      "          3       0.95      0.97      0.96        37\n",
      "          4       1.00      0.97      0.99        40\n",
      "          5       0.95      1.00      0.98        41\n",
      "          6       1.00      0.98      0.99        50\n",
      "          7       0.98      0.98      0.98        46\n",
      "          8       0.95      0.97      0.96        36\n",
      "          9       0.94      0.92      0.93        50\n",
      "\n",
      "avg / total       0.98      0.98      0.98       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"EVALUATION ON TESTING DATA | Model = 3\")\n",
    "print(classification_report(predictions3, testLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION ON TESTING DATA | Model = 4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        52\n",
      "          1       1.00      0.98      0.99        51\n",
      "          2       1.00      0.98      0.99        48\n",
      "          3       0.95      0.97      0.96        37\n",
      "          4       1.00      0.97      0.99        40\n",
      "          5       0.95      1.00      0.98        41\n",
      "          6       1.00      0.98      0.99        50\n",
      "          7       1.00      0.98      0.99        47\n",
      "          8       0.92      0.97      0.94        35\n",
      "          9       0.94      0.94      0.94        49\n",
      "\n",
      "avg / total       0.98      0.98      0.98       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"EVALUATION ON TESTING DATA | Model = 4\")\n",
    "print(classification_report(predictions4, testLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION ON TESTING DATA | Model = 5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        52\n",
      "          1       1.00      0.98      0.99        51\n",
      "          2       1.00      0.98      0.99        48\n",
      "          3       0.92      0.97      0.95        36\n",
      "          4       0.97      0.97      0.97        39\n",
      "          5       0.95      0.98      0.96        42\n",
      "          6       1.00      0.98      0.99        50\n",
      "          7       1.00      0.96      0.98        48\n",
      "          8       0.92      0.97      0.94        35\n",
      "          9       0.94      0.94      0.94        49\n",
      "\n",
      "avg / total       0.97      0.97      0.97       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"EVALUATION ON TESTING DATA | Model = 5\")\n",
    "print(classification_report(predictions5, testLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, there is no significant differences between the three result. All the calculation result are almost the same with only slightly different in the average of accuracy between model = 5 and the other two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply SVM Classifier\n",
    "\n",
    "Apply an SVM classifier.  Again, report the confusion matrix, as well as the accuracy, sensitivity, specificity, precision and negative predictive value.  How does the SVN classifier compare to the KNN classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this task first we wll need to import the svm library which we will already imported in the previous session and change the classfier into svm.\n",
    "\n",
    "Apply the SVM classifier to train and predict the data. We will print out the confusion matrix and the accuracy score in this part. The confusion matrix was used to evaluate the accuracy of a classification. The accuracy score will show how accurate the prediction is. Different from the KNN classifier, SVM does not need model or number of neighbor to proceed the classification process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will declare the svm classifier and do the training and testing of the prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcclassifier = svm.SVC() #declare the svm classifier\n",
    "svcclassifier.fit(trainImages, trainLabels) # do the training\n",
    "y_pred = svcclassifier.predict(testImages)  # predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will print out the confusion matrix and the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[19  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 12  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 11  0  0  0  0  0  0  0]\n",
      " [33 38 36 38 13 26 28 35 33 43]\n",
      " [ 0  0  0  0 26  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 17  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 21  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 11  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  4  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  6]]\n",
      "Accuracy Score:\n",
      "0.36666666666666664\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_pred, testLabels))  \n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_pred, testLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above result shows that the prediction is 36 percent accurate. Which is quite smaller compare to the result from KNN classsfier.\n",
    "\n",
    "We can also construct the confusion matrix by using a loop shown in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix code for 10x10\n",
    "C = np.empty([10,10])\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        C[i,j] = np.sum(np.logical_and(y_pred==i, testLabels==j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will continue to the next set of task that was mentioned in the question which is reporting the accuracy, sensitivity, specificity, precision and negative predictive value using functions.\n",
    "\n",
    "The following code will first define the false positive, false negative, true positive and true negative value. Then it will call the function that we built in the previous question and will print out the result of each. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is use to define the variable or argument to be used to call the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the value\n",
    "fp4 = C.sum(axis=0)-np.diag(C)\n",
    "fn4 = C.sum(axis=1)-np.diag(C)\n",
    "tp4 = np.diag(C)\n",
    "tn4 = C.sum()-np.diag(fp + fn + tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will call the function that we previously declared. It will then convert the value in the form of dataframe to make the display become more visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc4 = pd.DataFrame(accuracy(tp4,fp4,tn4,fn4))\n",
    "rec4 = pd.DataFrame(recall(tp4,fp4,tn4,fn4))\n",
    "speci4 = pd.DataFrame(specificity(tp4,fp4,tn4,fn4))\n",
    "prec4 = pd.DataFrame(precision(tp4,fp4,tn4,fn4))\n",
    "negative4 = pd.DataFrame(NegativePredictiveValue(tp4,fp4,tn4,fn4))\n",
    "f1score4 = pd.DataFrame(f1_score(tp4,fp4,tn4,fn4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will print out the result from the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################\n",
      "Accuracy: \n",
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.926667  0.924000  0.927565  0.631307  0.973415  0.947262  0.943888   \n",
      "1  0.934263  0.915367  0.927565  0.631307  0.973415  0.947262  0.943888   \n",
      "2  0.934263  0.924000  0.920000  0.631307  0.973415  0.947262  0.943888   \n",
      "3  0.934263  0.924000  0.927565  0.611717  0.973415  0.947262  0.943888   \n",
      "4  0.934263  0.924000  0.927565  0.631307  0.971047  0.947262  0.943888   \n",
      "5  0.934263  0.924000  0.927565  0.631307  0.973415  0.942222  0.943888   \n",
      "6  0.934263  0.924000  0.927565  0.631307  0.973415  0.947262  0.937639   \n",
      "7  0.934263  0.924000  0.927565  0.631307  0.973415  0.947262  0.943888   \n",
      "8  0.934263  0.924000  0.927565  0.631307  0.973415  0.947262  0.943888   \n",
      "9  0.934263  0.924000  0.927565  0.631307  0.973415  0.947262  0.943888   \n",
      "\n",
      "          7         8         9  \n",
      "0  0.929435  0.932238  0.913828  \n",
      "1  0.929435  0.932238  0.913828  \n",
      "2  0.929435  0.932238  0.913828  \n",
      "3  0.929435  0.932238  0.913828  \n",
      "4  0.929435  0.932238  0.913828  \n",
      "5  0.929435  0.932238  0.913828  \n",
      "6  0.929435  0.932238  0.913828  \n",
      "7  0.922049  0.932238  0.913828  \n",
      "8  0.929435  0.926503  0.913828  \n",
      "9  0.929435  0.932238  0.903587  \n",
      "####################################################################\n",
      "Recall: \n",
      "          0\n",
      "0  1.000000\n",
      "1  1.000000\n",
      "2  1.000000\n",
      "3  0.117647\n",
      "4  1.000000\n",
      "5  1.000000\n",
      "6  1.000000\n",
      "7  1.000000\n",
      "8  1.000000\n",
      "9  1.000000\n",
      "####################################################################\n",
      "Specificity: \n",
      "          0         1         2    3         4         5         6         7  \\\n",
      "0  0.923434  0.922131  0.925926  1.0  0.971922  0.945378  0.941423  0.927835   \n",
      "1  0.931677  0.913043  0.925926  1.0  0.971922  0.945378  0.941423  0.927835   \n",
      "2  0.931677  0.922131  0.917995  1.0  0.971922  0.945378  0.941423  0.927835   \n",
      "3  0.931677  0.922131  0.925926  1.0  0.971922  0.945378  0.941423  0.927835   \n",
      "4  0.931677  0.922131  0.925926  1.0  0.969267  0.945378  0.941423  0.927835   \n",
      "5  0.931677  0.922131  0.925926  1.0  0.971922  0.939954  0.941423  0.927835   \n",
      "6  0.931677  0.922131  0.925926  1.0  0.971922  0.945378  0.934579  0.927835   \n",
      "7  0.931677  0.922131  0.925926  1.0  0.971922  0.945378  0.941423  0.920091   \n",
      "8  0.931677  0.922131  0.925926  1.0  0.971922  0.945378  0.941423  0.927835   \n",
      "9  0.931677  0.922131  0.925926  1.0  0.971922  0.945378  0.941423  0.927835   \n",
      "\n",
      "          8         9  \n",
      "0  0.931677  0.912779  \n",
      "1  0.931677  0.912779  \n",
      "2  0.931677  0.912779  \n",
      "3  0.931677  0.912779  \n",
      "4  0.931677  0.912779  \n",
      "5  0.931677  0.912779  \n",
      "6  0.931677  0.912779  \n",
      "7  0.931677  0.912779  \n",
      "8  0.925843  0.912779  \n",
      "9  0.931677  0.902273  \n",
      "####################################################################\n",
      "Precision: \n",
      "          0\n",
      "0  0.365385\n",
      "1  0.240000\n",
      "2  0.234043\n",
      "3  1.000000\n",
      "4  0.666667\n",
      "5  0.395349\n",
      "6  0.428571\n",
      "7  0.239130\n",
      "8  0.108108\n",
      "9  0.122449\n",
      "####################################################################\n",
      "Negative Predictive Value: \n",
      "     0    1    2         3    4    5    6    7    8    9\n",
      "0  1.0  1.0  1.0  0.612245  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "1  1.0  1.0  1.0  0.612245  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "2  1.0  1.0  1.0  0.612245  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "3  1.0  1.0  1.0  0.590517  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "4  1.0  1.0  1.0  0.612245  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "5  1.0  1.0  1.0  0.612245  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "6  1.0  1.0  1.0  0.612245  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "7  1.0  1.0  1.0  0.612245  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "8  1.0  1.0  1.0  0.612245  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "9  1.0  1.0  1.0  0.612245  1.0  1.0  1.0  1.0  1.0  1.0\n",
      "####################################################################\n",
      "F1 Score:\n",
      "          0\n",
      "0  0.535211\n",
      "1  0.387097\n",
      "2  0.379310\n",
      "3  0.210526\n",
      "4  0.800000\n",
      "5  0.566667\n",
      "6  0.600000\n",
      "7  0.385965\n",
      "8  0.195122\n",
      "9  0.218182\n",
      "####################################################################\n"
     ]
    }
   ],
   "source": [
    "print(\"####################################################################\")\n",
    "print(\"Accuracy: \")\n",
    "print(acc4)\n",
    "print(\"####################################################################\")\n",
    "print(\"Recall: \")\n",
    "print(rec4)\n",
    "print(\"####################################################################\")\n",
    "print(\"Specificity: \")\n",
    "print(speci4)\n",
    "print(\"####################################################################\")\n",
    "print(\"Precision: \")\n",
    "print(prec4)\n",
    "print(\"####################################################################\")\n",
    "print(\"Negative Predictive Value: \")\n",
    "print(negative4)\n",
    "print(\"####################################################################\")\n",
    "print(\"F1 Score:\")\n",
    "print(f1score4)\n",
    "print(\"####################################################################\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also able to directly display the precision, recall, f1 score, and support by using classification_report function. The code below will do the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.37      0.54        52\n",
      "          1       1.00      0.24      0.39        50\n",
      "          2       1.00      0.23      0.38        47\n",
      "          3       0.12      1.00      0.21        38\n",
      "          4       1.00      0.67      0.80        39\n",
      "          5       1.00      0.40      0.57        43\n",
      "          6       1.00      0.43      0.60        49\n",
      "          7       1.00      0.24      0.39        46\n",
      "          8       1.00      0.11      0.20        37\n",
      "          9       1.00      0.12      0.22        49\n",
      "\n",
      "avg / total       0.93      0.37      0.43       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testLabels, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, although the accuracy score of KNN was shown to be higher than svm classifier, the SVM classifier is more easy to use and more accurate. The KNN result might be affected by outliers and it needs approximation to the nearest neihbour. On the other hand, SVM can handle the outliers, so their result will not be affected by the existance of outliers. The SVM is much more faster than the KNN, while the KNN work depend on the number of observations and neighbours. The more sample you have the longer it tooks for KNN classifier to find the `k` nearest neighbor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
